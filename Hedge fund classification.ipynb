{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from NNDeep import DeepNN\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>period</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>...</th>\n",
       "      <th>c80</th>\n",
       "      <th>c81</th>\n",
       "      <th>c82</th>\n",
       "      <th>c83</th>\n",
       "      <th>c84</th>\n",
       "      <th>c85</th>\n",
       "      <th>c86</th>\n",
       "      <th>c87</th>\n",
       "      <th>c88</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>837771</td>\n",
       "      <td>train9</td>\n",
       "      <td>-2.535552</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.023122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073914</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011314</td>\n",
       "      <td>1.055360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>837789</td>\n",
       "      <td>train9</td>\n",
       "      <td>0.611008</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>-0.015117</td>\n",
       "      <td>-0.026797</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057885</td>\n",
       "      <td>0.198569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.084890</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.021597</td>\n",
       "      <td>-1.882289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>837821</td>\n",
       "      <td>train9</td>\n",
       "      <td>-0.084158</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>-0.017080</td>\n",
       "      <td>-0.028906</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025388</td>\n",
       "      <td>0.092343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122077</td>\n",
       "      <td>0.09243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009972</td>\n",
       "      <td>-0.417288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>837849</td>\n",
       "      <td>train9</td>\n",
       "      <td>-1.185109</td>\n",
       "      <td>-0.011085</td>\n",
       "      <td>-0.023120</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055605</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.030415</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.060834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>837850</td>\n",
       "      <td>train9</td>\n",
       "      <td>0.342375</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>-0.010284</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042416</td>\n",
       "      <td>-0.063021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136356</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032605</td>\n",
       "      <td>-0.822442</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id  period        c1        c2        c3        c4   c5   c6   c7  \\\n",
       "0   837771  train9 -2.535552  0.000660 -0.000479  0.008932 -0.0  0.0  0.0   \n",
       "1   837789  train9  0.611008  0.016856 -0.015117 -0.026797 -0.0  0.0  0.0   \n",
       "2   837821  train9 -0.084158  0.013008 -0.017080 -0.028906 -0.0  0.0  0.0   \n",
       "3   837849  train9 -1.185109 -0.011085 -0.023120 -0.000092 -0.0  0.0  0.0   \n",
       "4   837850  train9  0.342375  0.006518  0.003716 -0.010284 -0.0  0.0  0.0   \n",
       "\n",
       "    c8   ...         c80       c81  c82       c83      c84  c85  c86  \\\n",
       "0  0.0   ...    0.016361  0.023122  0.0  0.073914  0.00000  0.0  0.0   \n",
       "1  0.0   ...    0.057885  0.198569  0.0 -0.084890  0.00000  0.0  0.0   \n",
       "2  0.0   ...   -0.025388  0.092343  0.0  0.122077  0.09243  0.0  0.0   \n",
       "3  0.0   ...   -0.055605  0.003650  0.0 -0.030415  0.00000  0.0  0.0   \n",
       "4  0.0   ...    0.042416 -0.063021  0.0  0.136356  0.00000  0.0  0.0   \n",
       "\n",
       "        c87       c88  target  \n",
       "0 -0.011314  1.055360       0  \n",
       "1 -0.021597 -1.882289       0  \n",
       "2 -0.009972 -0.417288       1  \n",
       "3 -0.000050 -0.060834       0  \n",
       "4  0.032605 -0.822442       0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('deepanalytics_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X          c1        c2        c3        c4   c5   c6   c7   c8        c9  c10  \\\n",
      "0 -2.535552  0.000660 -0.000479  0.008932 -0.0  0.0  0.0  0.0 -0.005144 -0.0   \n",
      "1  0.611008  0.016856 -0.015117 -0.026797 -0.0  0.0  0.0  0.0 -0.065916 -0.0   \n",
      "2 -0.084158  0.013008 -0.017080 -0.028906 -0.0  0.0  0.0  0.0 -0.035424 -0.0   \n",
      "3 -1.185109 -0.011085 -0.023120 -0.000092 -0.0  0.0  0.0  0.0 -0.003681 -0.0   \n",
      "4  0.342375  0.006518  0.003716 -0.010284 -0.0  0.0  0.0  0.0 -0.007461 -0.0   \n",
      "\n",
      "     ...          c79       c80       c81  c82       c83      c84  c85  c86  \\\n",
      "0    ...    -0.121688  0.016361  0.023122  0.0  0.073914  0.00000  0.0  0.0   \n",
      "1    ...    -0.120094  0.057885  0.198569  0.0 -0.084890  0.00000  0.0  0.0   \n",
      "2    ...    -0.009884 -0.025388  0.092343  0.0  0.122077  0.09243  0.0  0.0   \n",
      "3    ...    -0.062372 -0.055605  0.003650  0.0 -0.030415  0.00000  0.0  0.0   \n",
      "4    ...     0.172567  0.042416 -0.063021  0.0  0.136356  0.00000  0.0  0.0   \n",
      "\n",
      "        c87       c88  \n",
      "0 -0.011314  1.055360  \n",
      "1 -0.021597 -1.882289  \n",
      "2 -0.009972 -0.417288  \n",
      "3 -0.000050 -0.060834  \n",
      "4  0.032605 -0.822442  \n",
      "\n",
      "[5 rows x 88 columns]\n",
      "y 0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df['target']\n",
    "X = df.drop(['data_id','period','target'],axis=1)\n",
    "print('X', X.head())\n",
    "print('y', y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y).reshape(len(X),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = DeepNN([88,200,100,200,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective epoch:  1.0\n",
      "Accuracy:  50.06 %\n",
      "Cost:  4.897407161838651 \n",
      "\n",
      "Effective epoch:  2.0\n",
      "Accuracy:  65.41 %\n",
      "Cost:  0.6252829613914974 \n",
      "\n",
      "Effective epoch:  3.0\n",
      "Accuracy:  78.03999999999999 %\n",
      "Cost:  0.4353409316873327 \n",
      "\n",
      "Effective epoch:  4.0\n",
      "Accuracy:  82.35 %\n",
      "Cost:  0.34132147848498035 \n",
      "\n",
      "Effective epoch:  5.0\n",
      "Accuracy:  84.27 %\n",
      "Cost:  0.3049779276552621 \n",
      "\n",
      "Effective epoch:  6.0\n",
      "Accuracy:  86.15 %\n",
      "Cost:  0.2708079347180343 \n",
      "\n",
      "Effective epoch:  7.0\n",
      "Accuracy:  87.72 %\n",
      "Cost:  0.24284382045006384 \n",
      "\n",
      "Effective epoch:  8.0\n",
      "Accuracy:  88.18 %\n",
      "Cost:  0.2559390670083055 \n",
      "\n",
      "Effective epoch:  9.0\n",
      "Accuracy:  88.35 %\n",
      "Cost:  0.22469379890522365 \n",
      "\n",
      "Effective epoch:  10.0\n",
      "Accuracy:  88.82 %\n",
      "Cost:  0.21750108326024478 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohakamg/Desktop/Machine_Learning/Random/DeepNet/NNDeep.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective epoch:  11.0\n",
      "Accuracy:  90.09 %\n",
      "Cost:  0.20482044743518754 \n",
      "\n",
      "Effective epoch:  12.0\n",
      "Accuracy:  89.25999999999999 %\n",
      "Cost:  0.2062194011147005 \n",
      "\n",
      "Effective epoch:  13.0\n",
      "Accuracy:  91.7 %\n",
      "Cost:  0.164570478848352 \n",
      "\n",
      "Effective epoch:  14.0\n",
      "Accuracy:  91.86 %\n",
      "Cost:  0.1571952009291212 \n",
      "\n",
      "Effective epoch:  15.0\n",
      "Accuracy:  91.18 %\n",
      "Cost:  0.17280795667476814 \n",
      "\n",
      "Effective epoch:  16.0\n",
      "Accuracy:  91.25 %\n",
      "Cost:  0.1804588164019157 \n",
      "\n",
      "Effective epoch:  17.0\n",
      "Accuracy:  91.99000000000001 %\n",
      "Cost:  0.14864273155087154 \n",
      "\n",
      "Effective epoch:  18.0\n",
      "Accuracy:  92.47999999999999 %\n",
      "Cost:  0.16155648251122143 \n",
      "\n",
      "Effective epoch:  19.0\n",
      "Accuracy:  92.47 %\n",
      "Cost:  0.1577690583352178 \n",
      "\n",
      "Effective epoch:  20.0\n",
      "Accuracy:  92.24 %\n",
      "Cost:  0.16061418421471296 \n",
      "\n",
      "Time Taken:  150.59764790534973  seconds\n"
     ]
    }
   ],
   "source": [
    "w = NN.learn(200000, 0.01, X, y, ['reLU','sigmoid','sigmoid','sigmoid'], 'log_loss', 10000, 'sgd', 10, split=False, test_size=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  93.32000000000001 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohakamg/Desktop/Machine_Learning/Random/DeepNet/NNDeep.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ',np.mean(np.round(NN.think(X))==y) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Keras </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohakamg/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN.add(Dense(units=200, activation='relu',input_dim = 88, kernel_initializer = 'uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN.add(Dense(units=100, activation='sigmoid', kernel_initializer = 'uniform'))\n",
    "ANN.add(Dense(units=200, activation='sigmoid', kernel_initializer = 'uniform'))\n",
    "ANN.add(Dense(units=1, activation='sigmoid', kernel_initializer = 'uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 3s 285us/step - loss: 0.5559 - acc: 0.7169\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 3s 253us/step - loss: 0.5363 - acc: 0.7286\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 3s 253us/step - loss: 0.5250 - acc: 0.7345\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 3s 260us/step - loss: 0.5045 - acc: 0.7542\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 3s 283us/step - loss: 0.4914 - acc: 0.7583\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 3s 288us/step - loss: 0.4721 - acc: 0.7737\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 3s 277us/step - loss: 0.4582 - acc: 0.7850\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 3s 306us/step - loss: 0.4490 - acc: 0.7908\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 3s 296us/step - loss: 0.4337 - acc: 0.8009\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 3s 286us/step - loss: 0.4187 - acc: 0.8082\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 3s 270us/step - loss: 0.4050 - acc: 0.8144\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 3s 276us/step - loss: 0.3965 - acc: 0.8207\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 3s 269us/step - loss: 0.3866 - acc: 0.8270\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.3747 - acc: 0.8376\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 3s 282us/step - loss: 0.3660 - acc: 0.8405\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 3s 276us/step - loss: 0.3563 - acc: 0.8404\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 3s 278us/step - loss: 0.3484 - acc: 0.8468\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 3s 291us/step - loss: 0.3412 - acc: 0.8478\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 3s 283us/step - loss: 0.3366 - acc: 0.8524\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 3s 291us/step - loss: 0.3242 - acc: 0.8591\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.3196 - acc: 0.8634\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.3175 - acc: 0.8614\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 3s 287us/step - loss: 0.3072 - acc: 0.8688\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 3s 302us/step - loss: 0.3020 - acc: 0.8698\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 3s 295us/step - loss: 0.2953 - acc: 0.8734\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.2886 - acc: 0.8754\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 3s 289us/step - loss: 0.2865 - acc: 0.8778\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 3s 290us/step - loss: 0.2778 - acc: 0.8809\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 3s 277us/step - loss: 0.2763 - acc: 0.8822\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 3s 293us/step - loss: 0.2671 - acc: 0.8869\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 3s 282us/step - loss: 0.2661 - acc: 0.8866\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 3s 278us/step - loss: 0.2611 - acc: 0.8886\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 3s 287us/step - loss: 0.2635 - acc: 0.8892\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 3s 288us/step - loss: 0.2504 - acc: 0.8930\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 3s 283us/step - loss: 0.2484 - acc: 0.8978\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.2447 - acc: 0.8982\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 3s 285us/step - loss: 0.2421 - acc: 0.9027\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 3s 285us/step - loss: 0.2347 - acc: 0.9050\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 3s 313us/step - loss: 0.2348 - acc: 0.9021\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 3s 287us/step - loss: 0.2388 - acc: 0.9006\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 3s 283us/step - loss: 0.2287 - acc: 0.9021\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 3s 308us/step - loss: 0.2238 - acc: 0.9070\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 3s 334us/step - loss: 0.2262 - acc: 0.9051\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 3s 312us/step - loss: 0.2160 - acc: 0.9097\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 3s 299us/step - loss: 0.2188 - acc: 0.9103\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 3s 311us/step - loss: 0.2143 - acc: 0.9125\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 3s 316us/step - loss: 0.2100 - acc: 0.9115\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 3s 328us/step - loss: 0.2086 - acc: 0.9133\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2094 - acc: 0.9131\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 3s 330us/step - loss: 0.1981 - acc: 0.9169\n",
      "Time Taken for Keras:  146.6171269416809  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "ANN.fit(X,y,batch_size=10,epochs=50)\n",
    "end = time.time()\n",
    "print('Time Taken for Keras: ', end-start, ' seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
