{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from NNDeep import DeepNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>period</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>...</th>\n",
       "      <th>c80</th>\n",
       "      <th>c81</th>\n",
       "      <th>c82</th>\n",
       "      <th>c83</th>\n",
       "      <th>c84</th>\n",
       "      <th>c85</th>\n",
       "      <th>c86</th>\n",
       "      <th>c87</th>\n",
       "      <th>c88</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>837771</td>\n",
       "      <td>train9</td>\n",
       "      <td>-2.535552</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.023122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073914</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011314</td>\n",
       "      <td>1.055360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>837789</td>\n",
       "      <td>train9</td>\n",
       "      <td>0.611008</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>-0.015117</td>\n",
       "      <td>-0.026797</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057885</td>\n",
       "      <td>0.198569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.084890</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.021597</td>\n",
       "      <td>-1.882289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>837821</td>\n",
       "      <td>train9</td>\n",
       "      <td>-0.084158</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>-0.017080</td>\n",
       "      <td>-0.028906</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025388</td>\n",
       "      <td>0.092343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122077</td>\n",
       "      <td>0.09243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009972</td>\n",
       "      <td>-0.417288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>837849</td>\n",
       "      <td>train9</td>\n",
       "      <td>-1.185109</td>\n",
       "      <td>-0.011085</td>\n",
       "      <td>-0.023120</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055605</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.030415</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.060834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>837850</td>\n",
       "      <td>train9</td>\n",
       "      <td>0.342375</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>-0.010284</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042416</td>\n",
       "      <td>-0.063021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136356</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032605</td>\n",
       "      <td>-0.822442</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id  period        c1        c2        c3        c4   c5   c6   c7  \\\n",
       "0   837771  train9 -2.535552  0.000660 -0.000479  0.008932 -0.0  0.0  0.0   \n",
       "1   837789  train9  0.611008  0.016856 -0.015117 -0.026797 -0.0  0.0  0.0   \n",
       "2   837821  train9 -0.084158  0.013008 -0.017080 -0.028906 -0.0  0.0  0.0   \n",
       "3   837849  train9 -1.185109 -0.011085 -0.023120 -0.000092 -0.0  0.0  0.0   \n",
       "4   837850  train9  0.342375  0.006518  0.003716 -0.010284 -0.0  0.0  0.0   \n",
       "\n",
       "    c8   ...         c80       c81  c82       c83      c84  c85  c86  \\\n",
       "0  0.0   ...    0.016361  0.023122  0.0  0.073914  0.00000  0.0  0.0   \n",
       "1  0.0   ...    0.057885  0.198569  0.0 -0.084890  0.00000  0.0  0.0   \n",
       "2  0.0   ...   -0.025388  0.092343  0.0  0.122077  0.09243  0.0  0.0   \n",
       "3  0.0   ...   -0.055605  0.003650  0.0 -0.030415  0.00000  0.0  0.0   \n",
       "4  0.0   ...    0.042416 -0.063021  0.0  0.136356  0.00000  0.0  0.0   \n",
       "\n",
       "        c87       c88  target  \n",
       "0 -0.011314  1.055360       0  \n",
       "1 -0.021597 -1.882289       0  \n",
       "2 -0.009972 -0.417288       1  \n",
       "3 -0.000050 -0.060834       0  \n",
       "4  0.032605 -0.822442       0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('deepanalytics_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X          c1        c2        c3        c4   c5   c6   c7   c8        c9  c10  \\\n",
      "0 -2.535552  0.000660 -0.000479  0.008932 -0.0  0.0  0.0  0.0 -0.005144 -0.0   \n",
      "1  0.611008  0.016856 -0.015117 -0.026797 -0.0  0.0  0.0  0.0 -0.065916 -0.0   \n",
      "2 -0.084158  0.013008 -0.017080 -0.028906 -0.0  0.0  0.0  0.0 -0.035424 -0.0   \n",
      "3 -1.185109 -0.011085 -0.023120 -0.000092 -0.0  0.0  0.0  0.0 -0.003681 -0.0   \n",
      "4  0.342375  0.006518  0.003716 -0.010284 -0.0  0.0  0.0  0.0 -0.007461 -0.0   \n",
      "\n",
      "     ...          c79       c80       c81  c82       c83      c84  c85  c86  \\\n",
      "0    ...    -0.121688  0.016361  0.023122  0.0  0.073914  0.00000  0.0  0.0   \n",
      "1    ...    -0.120094  0.057885  0.198569  0.0 -0.084890  0.00000  0.0  0.0   \n",
      "2    ...    -0.009884 -0.025388  0.092343  0.0  0.122077  0.09243  0.0  0.0   \n",
      "3    ...    -0.062372 -0.055605  0.003650  0.0 -0.030415  0.00000  0.0  0.0   \n",
      "4    ...     0.172567  0.042416 -0.063021  0.0  0.136356  0.00000  0.0  0.0   \n",
      "\n",
      "        c87       c88  \n",
      "0 -0.011314  1.055360  \n",
      "1 -0.021597 -1.882289  \n",
      "2 -0.009972 -0.417288  \n",
      "3 -0.000050 -0.060834  \n",
      "4  0.032605 -0.822442  \n",
      "\n",
      "[5 rows x 88 columns]\n",
      "y 0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df['target']\n",
    "X = df.drop(['data_id','period','target'],axis=1)\n",
    "print('X', X.head())\n",
    "print('y', y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y).reshape(len(X),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = DeepNN([88,200,100,200,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  49.9 %\n",
      "Cost:  8.228601178225624 \n",
      "\n",
      "Accuracy:  66.35555555555555 %\n",
      "Cost:  0.6197298328360213 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-82b39602a3d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'reLU'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'log_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Machine_Learning/Random/DeepNet/NNDeep.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, num_of_epochs, learning_rate, X, y, activations, cost_func, metrics_at, optimizer, batch_size, scaler_type, split, test_size)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0my_sgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_indics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforwardFeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackPropogate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_sgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforwardFeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Machine_Learning/Random/DeepNet/NNDeep.py\u001b[0m in \u001b[0;36mbackPropogate\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_func_flipped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m#                     print('Sigmoid Prime')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                     \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_flipped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoidPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_flipped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_func_flipped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'reLU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;31m#                     print('reLU Prime')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Machine_Learning/Random/DeepNet/NNDeep.py\u001b[0m in \u001b[0;36msigmoidPrime\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msigmoidPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w = NN.learn(100000, 0.01, X, y, ['reLU','sigmoid','sigmoid','sigmoid'], 'log_loss', 1000, 'sgd', 100, split=False, test_size=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.18 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ',np.mean(np.round(NN.think(X))==y) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Keras </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohakamg/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN.add(Dense(units=200, activation='relu',input_dim = 88, kernel_initializer = 'uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN.add(Dense(units=100, activation='sigmoid', kernel_initializer = 'uniform'))\n",
    "ANN.add(Dense(units=200, activation='sigmoid', kernel_initializer = 'uniform'))\n",
    "ANN.add(Dense(units=1, activation='sigmoid', kernel_initializer = 'uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 3s 295us/step - loss: 0.6935 - acc: 0.5223\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 3s 260us/step - loss: 0.6781 - acc: 0.5692\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 3s 262us/step - loss: 0.6681 - acc: 0.5917\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 3s 252us/step - loss: 0.6525 - acc: 0.6197\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 3s 250us/step - loss: 0.6387 - acc: 0.6338\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 3s 261us/step - loss: 0.6233 - acc: 0.6560\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 3s 262us/step - loss: 0.6108 - acc: 0.6658\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 3s 261us/step - loss: 0.5951 - acc: 0.6788\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 3s 266us/step - loss: 0.5841 - acc: 0.6880\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.5632 - acc: 0.7108\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 3s 256us/step - loss: 0.5494 - acc: 0.7155\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 3s 272us/step - loss: 0.5342 - acc: 0.7308\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 3s 260us/step - loss: 0.5177 - acc: 0.7419\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 3s 252us/step - loss: 0.5057 - acc: 0.7533\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 3s 252us/step - loss: 0.4872 - acc: 0.7659\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 3s 254us/step - loss: 0.4712 - acc: 0.7776\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 3s 256us/step - loss: 0.4590 - acc: 0.7809\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 3s 257us/step - loss: 0.4421 - acc: 0.7919\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 3s 265us/step - loss: 0.4325 - acc: 0.8013\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 3s 258us/step - loss: 0.4205 - acc: 0.8064\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 3s 268us/step - loss: 0.4060 - acc: 0.8151\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 3s 263us/step - loss: 0.3939 - acc: 0.8242\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 3s 271us/step - loss: 0.3843 - acc: 0.8320\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 3s 266us/step - loss: 0.3749 - acc: 0.8341\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 3s 292us/step - loss: 0.3694 - acc: 0.8358\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 3s 269us/step - loss: 0.3609 - acc: 0.8421\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 3s 268us/step - loss: 0.3476 - acc: 0.8501\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 3s 270us/step - loss: 0.3436 - acc: 0.8503\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 3s 282us/step - loss: 0.3384 - acc: 0.8519\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 3s 275us/step - loss: 0.3243 - acc: 0.8573\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 3s 286us/step - loss: 0.3218 - acc: 0.8618\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 3s 267us/step - loss: 0.3110 - acc: 0.8655\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 3s 266us/step - loss: 0.3047 - acc: 0.8680\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 3s 272us/step - loss: 0.3019 - acc: 0.8718\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 3s 266us/step - loss: 0.2959 - acc: 0.8728\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 3s 283us/step - loss: 0.2945 - acc: 0.8734\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 3s 288us/step - loss: 0.2870 - acc: 0.8767\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 3s 283us/step - loss: 0.2823 - acc: 0.8779\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 3s 273us/step - loss: 0.2707 - acc: 0.8842\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 3s 275us/step - loss: 0.2744 - acc: 0.8840\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 3s 279us/step - loss: 0.2659 - acc: 0.8867\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 3s 291us/step - loss: 0.2655 - acc: 0.8873\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 3s 283us/step - loss: 0.2557 - acc: 0.8899\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.2509 - acc: 0.8951\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 3s 285us/step - loss: 0.2480 - acc: 0.8937\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.2444 - acc: 0.8984\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 3s 325us/step - loss: 0.2389 - acc: 0.9000\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 3s 298us/step - loss: 0.2365 - acc: 0.9001\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 3s 297us/step - loss: 0.2315 - acc: 0.9003\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 3s 339us/step - loss: 0.2239 - acc: 0.9053\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 3s 345us/step - loss: 0.2268 - acc: 0.9022\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 3s 305us/step - loss: 0.2289 - acc: 0.9001\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 3s 294us/step - loss: 0.2178 - acc: 0.9075\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 3s 297us/step - loss: 0.2168 - acc: 0.9098\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 3s 286us/step - loss: 0.2085 - acc: 0.9118\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 3s 285us/step - loss: 0.2122 - acc: 0.9088\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 3s 285us/step - loss: 0.2028 - acc: 0.9167\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 3s 286us/step - loss: 0.1991 - acc: 0.9161\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 3s 273us/step - loss: 0.2030 - acc: 0.9162\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 3s 271us/step - loss: 0.1993 - acc: 0.9153\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 3s 283us/step - loss: 0.2002 - acc: 0.9170\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 3s 295us/step - loss: 0.1903 - acc: 0.9199\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 3s 283us/step - loss: 0.1899 - acc: 0.9179\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 3s 278us/step - loss: 0.1903 - acc: 0.9198\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 3s 282us/step - loss: 0.1817 - acc: 0.9249\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 3s 278us/step - loss: 0.1835 - acc: 0.9240\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 3s 271us/step - loss: 0.1839 - acc: 0.9207\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 3s 282us/step - loss: 0.1793 - acc: 0.9246\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 3s 307us/step - loss: 0.1758 - acc: 0.9250\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.1742 - acc: 0.9267\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 3s 293us/step - loss: 0.1770 - acc: 0.9265\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 3s 284us/step - loss: 0.1676 - acc: 0.9324\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 3s 283us/step - loss: 0.1704 - acc: 0.9277\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 3s 319us/step - loss: 0.1672 - acc: 0.9283\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 3s 314us/step - loss: 0.1655 - acc: 0.9324\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 3s 320us/step - loss: 0.1613 - acc: 0.9337\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 3s 304us/step - loss: 0.1624 - acc: 0.9326\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 3s 301us/step - loss: 0.1577 - acc: 0.9334\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 3s 331us/step - loss: 0.1618 - acc: 0.9339\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 337us/step - loss: 0.1610 - acc: 0.9324\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 3s 295us/step - loss: 0.1532 - acc: 0.9361\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 3s 289us/step - loss: 0.1533 - acc: 0.9381\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 3s 293us/step - loss: 0.1498 - acc: 0.9403\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 3s 272us/step - loss: 0.1536 - acc: 0.9326\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 3s 269us/step - loss: 0.1489 - acc: 0.9389\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 3s 267us/step - loss: 0.1493 - acc: 0.9374\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 3s 274us/step - loss: 0.1461 - acc: 0.9403\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 3s 275us/step - loss: 0.1459 - acc: 0.9379\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 3s 266us/step - loss: 0.1504 - acc: 0.9361\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 3s 266us/step - loss: 0.1433 - acc: 0.9409\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 3s 269us/step - loss: 0.1349 - acc: 0.9446\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 3s 276us/step - loss: 0.1386 - acc: 0.9399\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 3s 285us/step - loss: 0.1412 - acc: 0.9421\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 3s 303us/step - loss: 0.1391 - acc: 0.9419\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 3s 338us/step - loss: 0.1349 - acc: 0.9457\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 3s 325us/step - loss: 0.1356 - acc: 0.9438\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 3s 290us/step - loss: 0.1316 - acc: 0.9471\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 3s 281us/step - loss: 0.1364 - acc: 0.9456\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 3s 289us/step - loss: 0.1302 - acc: 0.9480\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 3s 314us/step - loss: 0.1306 - acc: 0.9475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a0fa7e860>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN.fit(X,y,batch_size=10,epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
